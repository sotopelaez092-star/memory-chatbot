import os
from dotenv import load_dotenv
from llm.deepseek import DeepSeekLLM
from chatbot import MemoryChatbotWithCompressor
from memory.compressor import (
    SlidingWindowCompressor,
    LLMSummaryCompressor,
    HybridCompressor,
    TokenBasedCompressor
)


def print_header():
    """æ‰“å°ç¨‹åºå¤´éƒ¨"""
    print("\n" + "=" * 70)
    print("ğŸ§  Memory Chatbot v0.3 - å¸¦å‹ç¼©åŠŸèƒ½")
    print("=" * 70)
    print("åŠŸèƒ½è¯´æ˜:")
    print("  - æ”¯æŒ4ç§å‹ç¼©ç­–ç•¥")
    print("  - è‡ªåŠ¨ç®¡ç†å¯¹è¯ä¸Šä¸‹æ–‡")
    print("  - å®æ—¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯")
    print("\nå‘½ä»¤:")
    print("  'stats'    - æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯")
    print("  'clear'    - æ¸…ç©ºè®°å¿†")
    print("  'compress' - æŸ¥çœ‹å‹ç¼©ç­–ç•¥")
    print("  'switch'   - åˆ‡æ¢å‹ç¼©ç­–ç•¥")
    print("  'quit'     - é€€å‡ºç¨‹åº")
    print("=" * 70 + "\n")


def print_stats(bot: MemoryChatbotWithCompressor) -> None:
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    stats = bot.get_stats()
    print(f"\n{'='*70}")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    print(f"{'='*70}")
    print(f"å¯¹è¯è½®æ•°: {stats['turns']}")
    print(f"æ¶ˆæ¯æ•°é‡: {stats['messages']}")
    print(f"æ€»Tokenæ•°: {stats['total_tokens']}")
    print(f"è®°å¿†çŠ¶æ€: {'å·²æ»¡' if stats['is_full'] else 'æœªæ»¡'}")
    print(f"\nå‹ç¼©åŠŸèƒ½: {'å¯ç”¨' if stats['compression_enabled'] else 'ç¦ç”¨'}")
    if stats['compression_enabled']:
        print(f"å‹ç¼©ç­–ç•¥: {stats['compressor']}")
        print(f"å‹ç¼©æ¬¡æ•°: {stats['total_compressions']}")
        print(f"èŠ‚çœToken: {stats['tokens_saved']}")
        if stats['tokens_saved'] > 0:
            saved_cost = stats['tokens_saved'] / 1_000_000 * 0.14  # DeepSeekä»·æ ¼
            print(f"èŠ‚çœæˆæœ¬: ${saved_cost:.6f}")
    print(f"{'='*70}\n")


def choose_compressor(llm) -> tuple:
    """
    è®©ç”¨æˆ·é€‰æ‹©å‹ç¼©ç­–ç•¥
    
    Returns:
        (compressor, enable_compression)
    """
    print("\né€‰æ‹©å‹ç¼©ç­–ç•¥:")
    print("  1. ä¸ä½¿ç”¨å‹ç¼©ï¼ˆæœ€å¿«ï¼Œä½†å¯èƒ½ä¸¢å¤±å†å²ï¼‰")
    print("  2. æ»‘åŠ¨çª—å£ï¼ˆå¿«é€Ÿï¼Œå›ºå®šä¿ç•™æœ€è¿‘Nè½®ï¼‰")
    print("  3. LLMæ‘˜è¦ï¼ˆæ™ºèƒ½ï¼Œä¿ç•™è¯­ä¹‰ä¿¡æ¯ï¼‰")
    print("  4. æ··åˆç­–ç•¥ï¼ˆæ¨èï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ï¼‰")
    print("  5. TokenåŠ¨æ€ï¼ˆç²¾ç¡®æ§åˆ¶tokenæ•°é‡ï¼‰")
    
    while True:
        choice = input("\nè¯·é€‰æ‹© (1-5): ").strip()
        
        if choice == "1":
            return None, False
        elif choice == "2":
            keep_turns = int(input("ä¿ç•™æœ€è¿‘å‡ è½®ï¼Ÿ(é»˜è®¤5): ") or "5")
            return SlidingWindowCompressor(keep_turns=keep_turns), True
        elif choice == "3":
            keep_turns = int(input("ä¿ç•™æœ€è¿‘å‡ è½®å®Œæ•´å¯¹è¯ï¼Ÿ(é»˜è®¤3): ") or "3")
            return LLMSummaryCompressor(llm, keep_recent_turns=keep_turns), True
        elif choice == "4":
            threshold = int(input("æ‘˜è¦è§¦å‘é˜ˆå€¼ï¼ˆè½®æ•°ï¼‰ï¼Ÿ(é»˜è®¤10): ") or "10")
            keep_turns = int(input("ä¿ç•™æœ€è¿‘å‡ è½®ï¼Ÿ(é»˜è®¤3): ") or "3")
            return HybridCompressor(llm, threshold_turns=threshold, keep_recent_turns=keep_turns), True
        elif choice == "5":
            max_tokens = int(input("æœ€å¤§tokenæ•°ï¼Ÿ(é»˜è®¤4000): ") or "4000")
            return TokenBasedCompressor(llm.count_tokens, max_tokens=max_tokens), True
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")


def main():
    """å‘½ä»¤è¡ŒèŠå¤©ç¨‹åº"""
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # åˆå§‹åŒ–LLM
    print("æ­£åœ¨åˆå§‹åŒ–...")
    llm = DeepSeekLLM()
    
    # é€‰æ‹©å‹ç¼©ç­–ç•¥
    compressor, enable_compression = choose_compressor(llm)
    
    # åˆå§‹åŒ–Chatbot
    bot = MemoryChatbotWithCompressor(
        llm,
        system_prompt="ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚è¯·è®°ä½ç”¨æˆ·å‘Šè¯‰ä½ çš„ä¿¡æ¯ã€‚",
        max_turns=20,
        compressor=compressor,
        enable_compression=enable_compression,
        compression_trigger=10
    )
    
    # æ‰“å°å¤´éƒ¨
    print_header()
    
    if enable_compression:
        print(f"âœ… å·²å¯ç”¨å‹ç¼©: {compressor.__class__.__name__}\n")
    else:
        print(f"âš ï¸  æœªå¯ç”¨å‹ç¼©\n")
    
    # å¯¹è¯å¾ªç¯
    turn = 0
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            user_input = input(f"You [{turn}]: ").strip()
            
            # ç‰¹æ®Šå‘½ä»¤
            if user_input.lower() in ['quit', 'exit', 'q']:
                print("\nå†è§ï¼ğŸ‘‹")
                break
            
            if user_input.lower() == 'stats':
                print_stats(bot)
                continue
            
            if user_input.lower() == 'clear':
                bot.clear_history()
                turn = 0
                print("\nâœ… è®°å¿†å·²æ¸…ç©º\n")
                continue
            
            if user_input.lower() == 'compress':
                if bot.enable_compression:
                    print(f"\nå½“å‰å‹ç¼©ç­–ç•¥: {bot.compressor.__class__.__name__}")
                    print(f"å·²æ‰§è¡Œå‹ç¼©æ¬¡æ•°: {bot.stats['compressions']}")
                    print(f"å·²èŠ‚çœTokenæ•°: {bot.stats['tokens_saved']}\n")
                else:
                    print("\næœªå¯ç”¨å‹ç¼©\n")
                continue
            
            if user_input.lower() == 'switch':
                compressor, enable = choose_compressor(llm)
                if enable:
                    bot.set_compressor(compressor)
                    print(f"\nâœ… å·²åˆ‡æ¢åˆ°: {compressor.__class__.__name__}\n")
                else:
                    bot.enable_compression = False
                    print(f"\nâœ… å·²ç¦ç”¨å‹ç¼©\n")
                continue
            
            # ç©ºè¾“å…¥
            if not user_input:
                continue
            
            # è·å–å›å¤
            response = bot.chat(user_input)
            print(f"Bot [{turn}]: {response}\n")
            
            turn += 1
            
            # æ¯5è½®æ˜¾ç¤ºä¸€æ¬¡ç»Ÿè®¡
            if turn % 5 == 0:
                print_stats(bot)
            
        except KeyboardInterrupt:
            print("\n\nå†è§ï¼ğŸ‘‹")
            break
        except Exception as e:
            print(f"âŒ Error: {e}\n")


if __name__ == "__main__":
    main()