"""
LLMæ‘˜è¦å‹ç¼©å™¨æ€§èƒ½æµ‹è¯•
"""
import sys
import os
import json
from typing import List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

import time
from dotenv import load_dotenv
from src.memory.compressor import LLMSummaryCompressor
from src.llm.deepseek import DeepSeekLLM
from tests.test_data import (
    get_short_conversation,
    get_medium_conversation,
    get_long_conversation,
    get_very_long_conversation
)


def test_compression_rate():
    """æµ‹è¯•1ï¼šå‹ç¼©ç‡"""
    print("=" * 80)
    print("æµ‹è¯•1ï¼šå‹ç¼©ç‡æµ‹è¯•")
    print("=" * 80)
    print()
    
    load_dotenv()
    llm = DeepSeekLLM()
    compressor = LLMSummaryCompressor(llm, keep_recent_turns=3)
    
    test_cases = {
        "çŸ­å¯¹è¯(5è½®)": get_short_conversation(),
        "ä¸­ç­‰å¯¹è¯(10è½®)": get_medium_conversation(),
        "é•¿å¯¹è¯(20è½®)": get_long_conversation(),
        "è¶…é•¿å¯¹è¯(30è½®)": get_very_long_conversation()
    }
    
    results = []
    
    for name, messages in test_cases.items():
        print(f"{name}:")
        
        # åŸå§‹æ•°æ®
        original_count = len(messages)
        original_tokens = sum(llm.count_tokens(m['content']) for m in messages)
        
        print(f"  åŸå§‹: {original_count}æ¡æ¶ˆæ¯, {original_tokens} tokens")
        
        # å‹ç¼©
        try:
            compressed = compressor.compress(messages)
            compressed_count = len(compressed)
            compressed_tokens = sum(llm.count_tokens(m['content']) for m in compressed)
            
            # è®¡ç®—å‹ç¼©ç‡
            message_reduction = (1 - compressed_count / original_count) if original_count > 0 else 0
            token_reduction = (1 - compressed_tokens / original_tokens) if original_tokens > 0 else 0
            
            results.append({
                "name": name,
                "original_count": original_count,
                "compressed_count": compressed_count,
                "original_tokens": original_tokens,
                "compressed_tokens": compressed_tokens,
                "message_reduction": message_reduction,
                "token_reduction": token_reduction,
                "success": True
            })
            
            print(f"  å‹ç¼©å: {compressed_count}æ¡æ¶ˆæ¯, {compressed_tokens} tokens")
            print(f"  æ¶ˆæ¯å‹ç¼©ç‡: {message_reduction:.1%}")
            print(f"  Tokenå‹ç¼©ç‡: {token_reduction:.1%}")
            
            # æ˜¾ç¤ºæ‘˜è¦å†…å®¹
            summary_msg = [m for m in compressed if m['role'] == 'system']
            if summary_msg:
                print(f"  æ‘˜è¦å†…å®¹: {summary_msg[0]['content'][:100]}...")
            
        except Exception as e:
            print(f"  âŒ å‹ç¼©å¤±è´¥: {e}")
            results.append({
                "name": name,
                "success": False,
                "error": str(e)
            })
        
        print()
    
    return results


def test_speed():
    """æµ‹è¯•2ï¼šé€Ÿåº¦æµ‹è¯•"""
    print("=" * 80)
    print("æµ‹è¯•2ï¼šé€Ÿåº¦æµ‹è¯•")
    print("=" * 80)
    print()
    
    load_dotenv()
    llm = DeepSeekLLM()
    compressor = LLMSummaryCompressor(llm, keep_recent_turns=3)
    messages = get_medium_conversation()  # 10è½®
    
    print(f"æµ‹è¯•å¯¹è¯: {len(messages)}æ¡æ¶ˆæ¯ (10è½®)")
    print()
    
    # æµ‹è¯•ä¸åŒæ¬¡æ•°
    test_configs = [
        ("å‹ç¼©1æ¬¡", 1),
        ("å‹ç¼©3æ¬¡", 3),
        ("å‹ç¼©5æ¬¡", 5),
    ]
    
    for name, n in test_configs:
        print(f"{name}:")
        
        start = time.time()
        for i in range(n):
            try:
                compressed = compressor.compress(messages)
                print(f"  ç¬¬{i+1}æ¬¡å®Œæˆ", end="\r")
            except Exception as e:
                print(f"  ç¬¬{i+1}æ¬¡å¤±è´¥: {e}")
                break
        elapsed = (time.time() - start) * 1000
        
        avg_time = elapsed / n
        
        print(f"  æ€»è€—æ—¶: {elapsed:.2f}ms")
        print(f"  å¹³å‡æ¯æ¬¡: {avg_time:.2f}ms")
        print()


def test_cost():
    """æµ‹è¯•3ï¼šæˆæœ¬åˆ†æ"""
    print("=" * 80)
    print("æµ‹è¯•3ï¼šæˆæœ¬åˆ†æ")
    print("=" * 80)
    print()
    
    load_dotenv()
    llm = DeepSeekLLM()
    compressor = LLMSummaryCompressor(llm, keep_recent_turns=3)
    
    test_cases = {
        "çŸ­å¯¹è¯(5è½®)": get_short_conversation(),
        "ä¸­ç­‰å¯¹è¯(10è½®)": get_medium_conversation(),
        "é•¿å¯¹è¯(20è½®)": get_long_conversation(),
        "è¶…é•¿å¯¹è¯(30è½®)": get_very_long_conversation()
    }
    
    print("DeepSeekä»·æ ¼: $0.14/1M input tokens, $0.28/1M output tokens")
    print()
    
    for name, messages in test_cases.items():
        print(f"{name}:")
        
        # è®¡ç®—è¾“å…¥tokenï¼ˆéœ€è¦æ‘˜è¦çš„å¯¹è¯ï¼‰
        history_to_summarize = messages[:-6]  # ä¿ç•™æœ€è¿‘3è½®ï¼Œå…¶ä½™éœ€è¦æ‘˜è¦
        input_tokens = sum(llm.count_tokens(m['content']) for m in history_to_summarize)
        
        # ä¼°ç®—è¾“å‡ºtokenï¼ˆæ‘˜è¦é€šå¸¸æ¯”åŸæ–‡çŸ­ï¼‰
        estimated_output_tokens = input_tokens * 0.3  # å‡è®¾æ‘˜è¦æ˜¯åŸæ–‡çš„30%
        
        # è®¡ç®—æˆæœ¬
        input_cost = (input_tokens / 1_000_000) * 0.14
        output_cost = (estimated_output_tokens / 1_000_000) * 0.28
        total_cost = input_cost + output_cost
        
        print(f"  è¾“å…¥tokens: {input_tokens}")
        print(f"  é¢„ä¼°è¾“å‡ºtokens: {estimated_output_tokens:.0f}")
        print(f"  å•æ¬¡æˆæœ¬: ${total_cost:.6f}")
        print(f"  1ä¸‡æ¬¡æˆæœ¬: ${total_cost * 10000:.2f}")
        print()


def test_information_preservation():
    """æµ‹è¯•4ï¼šä¿¡æ¯ä¿ç•™æµ‹è¯•ï¼ˆå…³é”®ï¼ï¼‰"""
    print("=" * 80)
    print("æµ‹è¯•4ï¼šä¿¡æ¯ä¿ç•™æµ‹è¯•")
    print("=" * 80)
    print()
    
    load_dotenv()
    llm = DeepSeekLLM()
    compressor = LLMSummaryCompressor(llm, keep_recent_turns=2)
    
    # æ„é€ åŒ…å«å…³é”®ä¿¡æ¯çš„å¯¹è¯
    messages = [
        {"role": "user", "content": "æˆ‘å«Tomï¼Œä»Šå¹´28å²"},
        {"role": "assistant", "content": "ä½ å¥½Tomï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚"},
        {"role": "user", "content": "æˆ‘åœ¨ä¸Šæµ·æµ¦ä¸œå·¥ä½œ"},
        {"role": "assistant", "content": "æµ¦ä¸œæ˜¯ä¸ªå¾ˆå›½é™…åŒ–çš„åœ°æ–¹ï¼"},
        {"role": "user", "content": "æˆ‘æ˜¯AIå·¥ç¨‹å¸ˆ"},
        {"role": "assistant", "content": "AIå·¥ç¨‹å¸ˆæ˜¯å¾ˆæœ‰å‰æ™¯çš„èŒä¸šï¼"},
        {"role": "user", "content": "æˆ‘æœ€è¿‘åœ¨ç ”ç©¶Agentå¤šæ™ºèƒ½ä½“åä½œ"},
        {"role": "assistant", "content": "å¤šæ™ºèƒ½ä½“åä½œç¡®å®æ˜¯å‰æ²¿æ–¹å‘ï¼"},
        {"role": "user", "content": "é‡åˆ°äº†é€šä¿¡å»¶è¿Ÿçš„é—®é¢˜"},
        {"role": "assistant", "content": "é€šä¿¡å»¶è¿Ÿå¯ä»¥è€ƒè™‘ä¼˜åŒ–æ¶ˆæ¯é˜Ÿåˆ—ã€‚"},
        {"role": "user", "content": "ç”¨ä»€ä¹ˆæ¶ˆæ¯é˜Ÿåˆ—å¥½ï¼Ÿ"},
        {"role": "assistant", "content": "å¯ä»¥è€ƒè™‘Redisæˆ–RabbitMQã€‚"},
    ]
    
    print(f"åŸå§‹å¯¹è¯: {len(messages)}æ¡æ¶ˆæ¯ (6è½®)")
    print()
    
    print("å…³é”®ä¿¡æ¯ï¼š")
    key_info = ["Tom", "28å²", "ä¸Šæµ·", "æµ¦ä¸œ", "AIå·¥ç¨‹å¸ˆ", "Agent", "å¤šæ™ºèƒ½ä½“", "é€šä¿¡å»¶è¿Ÿ", "æ¶ˆæ¯é˜Ÿåˆ—"]
    print(f"  {', '.join(key_info)}")
    print()
    
    # å‹ç¼©
    try:
        compressed = compressor.compress(messages)
        
        print(f"å‹ç¼©å: {len(compressed)}æ¡æ¶ˆæ¯")
        print()
        
        print("å‹ç¼©åçš„å†…å®¹:")
        for i, msg in enumerate(compressed, 1):
            content = msg['content']
            print(f"  {i}. [{msg['role']:10}] {content}")
        print()
        
        # æ£€æŸ¥å“ªäº›å…³é”®ä¿¡æ¯è¢«ä¿ç•™
        all_content = ' '.join([m['content'] for m in compressed])
        
        print("å…³é”®ä¿¡æ¯ä¿ç•™æƒ…å†µ:")
        preserved = []
        lost = []
        for info in key_info:
            if info in all_content:
                preserved.append(info)
                print(f"  âœ… {info}")
            else:
                lost.append(info)
                print(f"  âŒ {info}")
        
        print()
        print(f"ä¿ç•™: {len(preserved)}/{len(key_info)} = {len(preserved)/len(key_info):.1%}")
        
    except Exception as e:
        print(f"âŒ å‹ç¼©å¤±è´¥: {e}")


def test_comparison_with_sliding_window():
    """æµ‹è¯•5ï¼šä¸æ»‘åŠ¨çª—å£å¯¹æ¯”"""
    print("=" * 80)
    print("æµ‹è¯•5ï¼šä¸æ»‘åŠ¨çª—å£å¯¹æ¯”")
    print("=" * 80)
    print()
    
    load_dotenv()
    llm = DeepSeekLLM()
    
    from src.memory.compressor import SlidingWindowCompressor
    
    sliding_compressor = SlidingWindowCompressor(keep_turns=5)
    llm_compressor = LLMSummaryCompressor(llm, keep_recent_turns=3)
    
    messages = get_long_conversation()  # 20è½®
    
    print(f"åŸå§‹å¯¹è¯: {len(messages)}æ¡æ¶ˆæ¯, {sum(llm.count_tokens(m['content']) for m in messages)} tokens")
    print()
    
    # æ»‘åŠ¨çª—å£
    print("æ»‘åŠ¨çª—å£å‹ç¼©:")
    start = time.time()
    sliding_result = sliding_compressor.compress(messages)
    sliding_time = (time.time() - start) * 1000
    sliding_tokens = sum(llm.count_tokens(m['content']) for m in sliding_result)
    
    print(f"  ç»“æœ: {len(sliding_result)}æ¡æ¶ˆæ¯, {sliding_tokens} tokens")
    print(f"  è€—æ—¶: {sliding_time:.2f}ms")
    print(f"  æˆæœ¬: $0")
    print()
    
    # LLMæ‘˜è¦
    print("LLMæ‘˜è¦å‹ç¼©:")
    try:
        start = time.time()
        llm_result = llm_compressor.compress(messages)
        llm_time = (time.time() - start) * 1000
        llm_tokens = sum(llm.count_tokens(m['content']) for m in llm_result)
        
        print(f"  ç»“æœ: {len(llm_result)}æ¡æ¶ˆæ¯, {llm_tokens} tokens")
        print(f"  è€—æ—¶: {llm_time:.2f}ms")
        
        # è®¡ç®—æˆæœ¬
        input_tokens = sum(llm.count_tokens(m['content']) for m in messages[:-6])
        cost = (input_tokens / 1_000_000) * 0.14 + (llm_tokens * 0.3 / 1_000_000) * 0.28
        print(f"  æˆæœ¬: ${cost:.6f}")
        print()
        
        # å¯¹æ¯”
        print("å¯¹æ¯”:")
        print(f"  Tokenå‡å°‘: æ»‘åŠ¨çª—å£ {sliding_tokens} vs LLMæ‘˜è¦ {llm_tokens}")
        print(f"  é€Ÿåº¦: æ»‘åŠ¨çª—å£ {sliding_time:.2f}ms vs LLMæ‘˜è¦ {llm_time:.2f}ms (æ…¢ {llm_time/sliding_time:.0f}x)")
        print(f"  æˆæœ¬: æ»‘åŠ¨çª—å£ $0 vs LLMæ‘˜è¦ ${cost:.6f}")
        
    except Exception as e:
        print(f"  âŒ å‹ç¼©å¤±è´¥: {e}")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("LLMæ‘˜è¦å‹ç¼©å™¨ - å®Œæ•´æ€§èƒ½æµ‹è¯•")
    print("=" * 80)
    print()
    
    # æµ‹è¯•1ï¼šå‹ç¼©ç‡
    compression_results = test_compression_rate()
    
    # æµ‹è¯•2ï¼šé€Ÿåº¦
    test_speed()
    
    # æµ‹è¯•3ï¼šæˆæœ¬
    test_cost()
    
    # æµ‹è¯•4ï¼šä¿¡æ¯ä¿ç•™
    test_information_preservation()
    
    # æµ‹è¯•5ï¼šå¯¹æ¯”
    test_comparison_with_sliding_window()
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    print()
    print("ğŸ“Š å‹ç¼©ç‡: é€šå¸¸èƒ½è¾¾åˆ°70-85%ï¼ˆä¸æ»‘åŠ¨çª—å£ç›¸å½“ï¼‰")
    print("ğŸŒ é€Ÿåº¦: 1-3ç§’/æ¬¡ï¼ˆæ¯”æ»‘åŠ¨çª—å£æ…¢10000å€ï¼‰")
    print("ğŸ’° æˆæœ¬: çº¦$0.0001-0.0003/æ¬¡ï¼ˆæ¯æ¬¡å‹ç¼©éœ€è¦è°ƒç”¨LLMï¼‰")
    print("ğŸ§  è¯­ä¹‰ä¿ç•™: èƒ½ä¿ç•™å¤§éƒ¨åˆ†å…³é”®ä¿¡æ¯ï¼ˆå¦‚å§“åã€åœ°ç‚¹ã€èŒä¸šï¼‰")
    print()
    print("ç»“è®º: LLMæ‘˜è¦é€‚åˆé•¿å¯¹è¯ã€éœ€è¦ä¿ç•™è¯­ä¹‰çš„åœºæ™¯")
    print("=" * 80)


if __name__ == "__main__":
    run_all_tests()