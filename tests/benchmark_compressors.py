"""
å‹ç¼©ç­–ç•¥æ€§èƒ½æµ‹è¯•
å¯¹æ¯”4ç§å‹ç¼©ç­–ç•¥çš„æ€§èƒ½è¡¨ç°
"""

import sys
import os
import time
import json
from typing import List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

from dotenv import load_dotenv

from src.llm.deepseek import DeepSeekLLM
from src.memory.compressor import (
    SlidingWindowCompressor,
    LLMSummaryCompressor,
    HybridCompressor,
    TokenBasedCompressor
)
from tests.test_data import (
    get_short_conversation,
    get_medium_conversation,
    get_long_conversation,
    get_very_long_conversation
)


class CompressorBenchmark:
    """å‹ç¼©å™¨æ€§èƒ½æµ‹è¯•"""
    
    def __init__(self, llm):
        self.llm = llm
        
        # åˆå§‹åŒ–4ç§å‹ç¼©å™¨
        self.compressors = {
            "SlidingWindow": SlidingWindowCompressor(keep_turns=5),
            "LLMSummary": LLMSummaryCompressor(llm, keep_recent_turns=3),
            "Hybrid": HybridCompressor(llm, threshold_turns=10, keep_recent_turns=3),
            "TokenBased": TokenBasedCompressor(llm.count_tokens, max_tokens=1000)
        }
        
        # æµ‹è¯•æ•°æ®é›†
        self.test_cases = {
            "çŸ­å¯¹è¯(5è½®)": get_short_conversation(),
            "ä¸­ç­‰å¯¹è¯(10è½®)": get_medium_conversation(),
            "é•¿å¯¹è¯(20è½®)": get_long_conversation(),
            "è¶…é•¿å¯¹è¯(30è½®)": get_very_long_conversation()
        }
    
    def test_single_compressor(self, 
                               name: str, 
                               compressor, 
                               messages: List[Dict],
                               repeat: int = 1) -> Dict:
        """
        æµ‹è¯•å•ä¸ªå‹ç¼©å™¨
        
        Args:
            name: å‹ç¼©å™¨åç§°
            compressor: å‹ç¼©å™¨å®ä¾‹
            messages: æµ‹è¯•æ¶ˆæ¯
            repeat: é‡å¤æ¬¡æ•°ï¼ˆç”¨äºæµ‹è¯•LLMæ‘˜è¦çš„ç¨³å®šæ€§ï¼‰
            
        Returns:
            æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        # åŸå§‹æ•°æ®
        original_count = len(messages)
        original_tokens = sum(self.llm.count_tokens(m['content']) for m in messages)
        
        # æ‰§è¡Œå‹ç¼©ï¼ˆå¤šæ¬¡æµ‹è¯•å–å¹³å‡ï¼‰
        total_time = 0
        compressed_results = []
        
        for _ in range(repeat):
            start = time.time()
            compressed = compressor.compress(messages)
            elapsed = time.time() - start
            total_time += elapsed
            compressed_results.append(compressed)
        
        avg_time = total_time / repeat
        
        # ä½¿ç”¨æœ€åä¸€æ¬¡çš„å‹ç¼©ç»“æœè®¡ç®—æŒ‡æ ‡
        compressed = compressed_results[-1]
        compressed_count = len(compressed)
        compressed_tokens = sum(self.llm.count_tokens(m['content']) for m in compressed)
        
        # è®¡ç®—å‹ç¼©ç‡
        message_reduction = (1 - compressed_count / original_count) if original_count > 0 else 0
        token_reduction = (1 - compressed_tokens / original_tokens) if original_tokens > 0 else 0
        
        # ä¼°ç®—æˆæœ¬ï¼ˆDeepSeek: $0.14/1M input tokensï¼‰
        cost = (original_tokens / 1_000_000) * 0.14 if name == "LLMSummary" else 0
        
        return {
            "compressor": name,
            "original_messages": original_count,
            "compressed_messages": compressed_count,
            "original_tokens": original_tokens,
            "compressed_tokens": compressed_tokens,
            "message_reduction": f"{message_reduction:.1%}",
            "token_reduction": f"{token_reduction:.1%}",
            "time_ms": f"{avg_time * 1000:.2f}",
            "cost_usd": f"${cost:.6f}"
        }
    
    def run_benchmark(self, repeat: int = 1) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„æ€§èƒ½æµ‹è¯•
        
        Args:
            repeat: æ¯ä¸ªæµ‹è¯•é‡å¤æ¬¡æ•°
            
        Returns:
            å®Œæ•´çš„æµ‹è¯•ç»“æœ
        """
        results = {}
        
        print("=" * 80)
        print("å‹ç¼©ç­–ç•¥æ€§èƒ½æµ‹è¯•")
        print("=" * 80)
        print(f"é‡å¤æ¬¡æ•°: {repeat}")
        print()
        
        for case_name, messages in self.test_cases.items():
            print(f"\n{'='*80}")
            print(f"æµ‹è¯•åœºæ™¯: {case_name}")
            print(f"{'='*80}")
            
            case_results = []
            
            for comp_name, compressor in self.compressors.items():
                print(f"\næµ‹è¯• {comp_name}...", end=" ")
                
                try:
                    result = self.test_single_compressor(
                        comp_name, 
                        compressor, 
                        messages,
                        repeat=repeat if comp_name == "LLMSummary" else 1
                    )
                    case_results.append(result)
                    print("âœ“")
                except Exception as e:
                    print(f"âœ— é”™è¯¯: {e}")
                    continue
            
            results[case_name] = case_results
            
            # æ‰“å°æœ¬åœºæ™¯çš„ç»“æœ
            self._print_case_results(case_name, case_results)
        
        return results
    
    def _print_case_results(self, case_name: str, results: List[Dict]):
        """æ‰“å°å•ä¸ªåœºæ™¯çš„ç»“æœ"""
        print(f"\n{case_name} - æµ‹è¯•ç»“æœ:")
        print("-" * 80)
        
        # è¡¨å¤´
        print(f"{'ç­–ç•¥':<15} {'æ¶ˆæ¯æ•°':<12} {'Tokenæ•°':<15} {'å‹ç¼©ç‡':<10} {'è€—æ—¶':<12} {'æˆæœ¬':<12}")
        print("-" * 80)
        
        # æ•°æ®è¡Œ
        for r in results:
            msg_str = f"{r['compressed_messages']}/{r['original_messages']}"
            token_str = f"{r['compressed_tokens']}/{r['original_tokens']}"
            
            print(f"{r['compressor']:<15} {msg_str:<12} {token_str:<15} "
                  f"{r['token_reduction']:<10} {r['time_ms']:<12} {r['cost_usd']:<12}")
    
    def save_results(self, results: Dict, filename: str = "benchmark_results.json"):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        filepath = os.path.join(project_root, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {filepath}")
    
    def print_summary(self, results: Dict):
        """æ‰“å°æ€»ç»“"""
        print("\n" + "=" * 80)
        print("æµ‹è¯•æ€»ç»“")
        print("=" * 80)
        
        print("\nğŸ“Š é€Ÿåº¦æ’åï¼ˆè¶Šå¿«è¶Šå¥½ï¼‰:")
        all_speeds = []
        for case_name, case_results in results.items():
            for r in case_results:
                time_val = float(r['time_ms'].replace('ms', ''))
                all_speeds.append((f"{r['compressor']}", time_val, case_name))
        
        all_speeds.sort(key=lambda x: x[1])
        for i, (name, speed, case) in enumerate(all_speeds[:8], 1):
            print(f"  {i}. {name:<15} {speed:.2f}ms ({case})")
        
        print("\nğŸ“‰ å‹ç¼©ç‡æ’åï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰:")
        all_compressions = []
        for case_name, case_results in results.items():
            if "é•¿å¯¹è¯" in case_name:  # åªçœ‹é•¿å¯¹è¯çš„å‹ç¼©æ•ˆæœ
                for r in case_results:
                    rate = float(r['token_reduction'].replace('%', ''))
                    all_compressions.append((r['compressor'], rate, case_name))
        
        all_compressions.sort(key=lambda x: x[1], reverse=True)
        for i, (name, rate, case) in enumerate(all_compressions, 1):
            print(f"  {i}. {name:<15} {rate:.1f}% ({case})")
        
        print("\nğŸ’° æˆæœ¬å¯¹æ¯”:")
        print("  SlidingWindow: $0 (æ— æˆæœ¬)")
        print("  TokenBased:    $0 (æ— æˆæœ¬)")
        print("  Hybrid:        $0-$0.0001 (æ ¹æ®å¯¹è¯é•¿åº¦)")
        print("  LLMSummary:    $0.0001-$0.0003 (æ¯æ¬¡å‹ç¼©)")
        
        print("\nğŸ¯ æ¨èä½¿ç”¨åœºæ™¯:")
        print("  SlidingWindow  â†’ çŸ­å¯¹è¯(<10è½®) + è¿½æ±‚æè‡´é€Ÿåº¦")
        print("  TokenBased     â†’ ä¸¥æ ¼tokené™åˆ¶ + è¿½æ±‚é€Ÿåº¦")
        print("  Hybrid         â†’ é€šç”¨åœºæ™¯ (æ¨è) â­")
        print("  LLMSummary     â†’ è¶…é•¿å¯¹è¯(>30è½®) + éœ€è¦ä¿ç•™è¯­ä¹‰")


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv(os.path.join(project_root, '.env'))
    
    print("\næ­£åœ¨åˆå§‹åŒ–...")
    try:
        llm = DeepSeekLLM()
        print("âœ“ LLMåˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âœ— LLMåˆå§‹åŒ–å¤±è´¥: {e}")
        print("\nè¯·ç¡®ä¿ï¼š")
        print("  1. .envæ–‡ä»¶å­˜åœ¨")
        print("  2. DEEPSEEK_API_KEYå·²é…ç½®")
        return
    
    benchmark = CompressorBenchmark(llm)
    
    # è¿è¡Œæµ‹è¯•
    print("\nå¼€å§‹æµ‹è¯•...")
    results = benchmark.run_benchmark(repeat=1)
    
    # æ‰“å°æ€»ç»“
    benchmark.print_summary(results)
    
    # ä¿å­˜ç»“æœ
    benchmark.save_results(results)
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)


if __name__ == "__main__":
    main()