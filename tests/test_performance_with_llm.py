"""
æ€§èƒ½æµ‹è¯• - çœŸå®žLLMåŽ‹ç¼©ï¼ˆå®Œæ•´ä¿®å¤ç‰ˆï¼‰
"""
import asyncio
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import asyncpg
import time
from typing import List, Dict
from dotenv import load_dotenv
import httpx
import json

from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
from src.memory.postgres_storage import PostgreSQLStorage
from src.memory.database import DatabaseManager
from src.memory.mid_term import MidTermMemory


# åŠ è½½çŽ¯å¢ƒå˜é‡
load_dotenv()

# æ•°æ®åº“é…ç½®
username = os.getenv("USER")
DB_HOST = "localhost"
DB_PORT = 5432
DB_NAME = "memory_chatbot_test"

DB_URL = f"postgresql+asyncpg://{username}@{DB_HOST}:{DB_PORT}/{DB_NAME}"


class MidTermMemoryWithLLM(MidTermMemory):
    """
    æ‰©å±•MidTermMemoryï¼Œæ·»åŠ çœŸå®žLLMåŽ‹ç¼©åŠŸèƒ½
    
    é€šè¿‡ç»§æ‰¿æ‰©å±•ï¼Œä¸ä¿®æ”¹åŽŸå§‹ä»£ç 
    """
    
    def __init__(
        self,
        storage,
        max_turns: int = 10,
        enable_real_compression: bool = False
    ):
        """åˆå§‹åŒ–"""
        from src.memory.short_term import ShortTermMemory
        
        # ç›´æŽ¥åˆå§‹åŒ–ï¼Œä¸è°ƒç”¨çˆ¶ç±»__init__ï¼ˆé¿å…bugï¼‰
        self.storage = storage
        self.short_term = ShortTermMemory(max_turns=max_turns)
        
        # æ·»åŠ LLMé…ç½®
        self.enable_real_compression = enable_real_compression
        self.api_key = os.getenv("DEEPSEEK_API_KEY")
        self.api_base = "https://api.deepseek.com/v1"
        
        if self.enable_real_compression and not self.api_key:
            print("âš ï¸  è­¦å‘Šï¼šæœªè®¾ç½®DEEPSEEK_API_KEYï¼Œå°†ä½¿ç”¨å‡åŽ‹ç¼©")
            self.enable_real_compression = False
    
    async def _generate_summary(self, messages: List) -> str:
        """é‡å†™çˆ¶ç±»æ–¹æ³•ï¼Œæ”¯æŒçœŸå®žLLMåŽ‹ç¼©"""
        if not self.enable_real_compression:
            # å‡åŽ‹ç¼©ï¼ˆä¸è°ƒç”¨LLMï¼‰
            user_count = sum(1 for m in messages if hasattr(m, 'role') and m.role == "user")
            assistant_count = sum(1 for m in messages if hasattr(m, 'role') and m.role == "assistant")
            return f"å¯¹è¯åŒ…å«{len(messages)}æ¡æ¶ˆæ¯ï¼Œç”¨æˆ·å‘é€äº†{user_count}æ¡ï¼ŒåŠ©æ‰‹å›žå¤äº†{assistant_count}æ¡ã€‚"
        
        # çœŸå®žLLMåŽ‹ç¼©
        try:
            return await self._generate_real_summary(messages)
        except Exception as e:
            print(f"âŒ LLMåŽ‹ç¼©å¤±è´¥: {e}")
            # é™çº§åˆ°å‡åŽ‹ç¼©
            user_count = sum(1 for m in messages if hasattr(m, 'role') and m.role == "user")
            assistant_count = sum(1 for m in messages if hasattr(m, 'role') and m.role == "assistant")
            return f"å¯¹è¯åŒ…å«{len(messages)}æ¡æ¶ˆæ¯ï¼Œç”¨æˆ·å‘é€äº†{user_count}æ¡ï¼ŒåŠ©æ‰‹å›žå¤äº†{assistant_count}æ¡ã€‚"
    
    async def _generate_real_summary(self, messages: List) -> str:
        """ä½¿ç”¨DeepSeekç”ŸæˆçœŸå®žæ‘˜è¦"""
        conversation_text = ""
        for msg in messages:
            role = msg.role if hasattr(msg, 'role') else "user"
            content = msg.content if hasattr(msg, 'content') else str(msg)
            conversation_text += f"{role}: {content}\n"
        
        prompt = f"""è¯·ç”¨1-2å¥è¯æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„æ ¸å¿ƒå†…å®¹ï¼š

{conversation_text}

æ€»ç»“ï¼š"""
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.api_base}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "deepseek-chat",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 200,
                    "temperature": 0.3
                },
                timeout=30.0
            )
            
            if response.status_code != 200:
                raise Exception(f"APIé”™è¯¯: {response.status_code} {response.text}")
            
            result = response.json()
            summary = result["choices"][0]["message"]["content"].strip()
            return summary
    
    async def _extract_user_profile(self, messages: List) -> Dict[str, str]:
        """é‡å†™çˆ¶ç±»æ–¹æ³•ï¼Œæ”¯æŒçœŸå®žLLMæå–"""
        if not self.enable_real_compression:
            return {}
        
        try:
            return await self._extract_real_profile(messages)
        except Exception as e:
            print(f"âŒ LLMç”»åƒæå–å¤±è´¥: {e}")
            return {}
    
    async def _extract_real_profile(self, messages: List) -> Dict[str, str]:
        """ä½¿ç”¨DeepSeekæå–çœŸå®žç”¨æˆ·ç”»åƒ"""
        user_messages = [m for m in messages if hasattr(m, 'role') and m.role == "user"]
        
        if not user_messages:
            return {}
        
        user_text = "\n".join([
            m.content if hasattr(m, 'content') else str(m) 
            for m in user_messages
        ])
        
        prompt = f"""åˆ†æžä»¥ä¸‹ç”¨æˆ·çš„å¯¹è¯ï¼Œæå–ç”¨æˆ·ç”»åƒä¿¡æ¯ã€‚

ç”¨æˆ·æ¶ˆæ¯ï¼š
{user_text}

è¯·ä»¥JSONæ ¼å¼è¿”å›žç”¨æˆ·ç”»åƒï¼ŒåŒ…æ‹¬ä½†ä¸é™äºŽï¼šname, age, location, interests, occupationç­‰ã€‚
å¦‚æžœæŸä¸ªä¿¡æ¯ä¸ç¡®å®šï¼Œä¸è¦åŒ…å«åœ¨JSONä¸­ã€‚åªè¿”å›žJSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚

ç¤ºä¾‹ï¼š
{{"name": "Tom", "age": "28", "location": "ä¸Šæµ·", "interests": "ç¼–ç¨‹,AI"}}

JSONï¼š"""
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.api_base}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "deepseek-chat",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 300,
                    "temperature": 0.1
                },
                timeout=30.0
            )
            
            if response.status_code != 200:
                raise Exception(f"APIé”™è¯¯: {response.status_code}")
            
            result = response.json()
            profile_text = result["choices"][0]["message"]["content"].strip()
            
            try:
                # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—
                if "```json" in profile_text:
                    profile_text = profile_text.split("```json")[1].split("```")[0].strip()
                elif "```" in profile_text:
                    profile_text = profile_text.split("```")[1].split("```")[0].strip()
                
                profile = json.loads(profile_text)
                
                # âœ… å…³é”®ä¿®å¤ï¼šè½¬æ¢æ‰€æœ‰å€¼ä¸ºå­—ç¬¦ä¸²
                profile_str = {k: str(v) for k, v in profile.items()}
                
                return profile_str
            except json.JSONDecodeError:
                print(f"âš ï¸  æ— æ³•è§£æžç”»åƒJSON: {profile_text}")
                return {}


async def ensure_database():
    """ç¡®ä¿æµ‹è¯•æ•°æ®åº“å­˜åœ¨"""
    conn = await asyncpg.connect(
        user=username,
        host=DB_HOST,
        port=DB_PORT,
        database='postgres'
    )
    
    try:
        exists = await conn.fetchval(
            f"SELECT 1 FROM pg_database WHERE datname='{DB_NAME}'"
        )
        
        if not exists:
            await conn.execute(f'CREATE DATABASE {DB_NAME}')
            print(f"âœ“ åˆ›å»ºæ•°æ®åº“ {DB_NAME}")
        else:
            print(f"âœ“ æ•°æ®åº“ {DB_NAME} å·²å­˜åœ¨")
    finally:
        await conn.close()


class LLMPerformanceTest:
    """LLMæ€§èƒ½æµ‹è¯•ï¼ˆå®Œæ•´ä¿®å¤ç‰ˆï¼‰"""
    
    def __init__(self):
        self.results = {}
        self.async_session_maker = None
        self.engine = None
    
    async def setup(self):
        """åˆå§‹åŒ–æµ‹è¯•çŽ¯å¢ƒ"""
        db_manager = DatabaseManager(DB_URL)
        try:
            await db_manager.drop_tables()
        except:
            pass
        await db_manager.create_tables()
        print("âœ“ æ•°æ®åº“è¡¨å·²åˆ›å»º")
        
        self.engine = create_async_engine(DB_URL, echo=False)
        self.async_session_maker = async_sessionmaker(
            self.engine, class_=AsyncSession, expire_on_commit=False
        )
    
    async def teardown(self):
        """æ¸…ç†"""
        if self.engine:
            await self.engine.dispose()
    
    async def test_fake_vs_real_compression(self):
        """
        æµ‹è¯•1ï¼šå‡åŽ‹ç¼© vs çœŸå®žLLMåŽ‹ç¼©ï¼ˆå®Œæ•´ä¿®å¤ç‰ˆï¼‰
        
        å…³é”®ä¿®å¤ï¼š
        1. ç¬¬ä¸€é˜¶æ®µï¼šæ·»åŠ 70æ¡ â†’ PostgreSQLæœ‰50æ¡ï¼Œè§¦å‘ç¬¬1æ¬¡åŽ‹ç¼©
        2. ç¬¬äºŒé˜¶æ®µï¼šæ·»åŠ 48æ¡ â†’ PostgreSQLæœ‰98æ¡
        3. ç¬¬ä¸‰é˜¶æ®µï¼šæ·»åŠ 2æ¡ â†’ PostgreSQLæœ‰100æ¡ï¼Œè§¦å‘ç¬¬2æ¬¡åŽ‹ç¼©ï¼ˆæµ‹é‡è¿™æ¬¡ï¼‰
        """
        print(f"\nã€æµ‹è¯•1ã€‘å‡åŽ‹ç¼© vs çœŸå®žLLMåŽ‹ç¼©ï¼ˆå®Œæ•´ä¿®å¤ç‰ˆï¼‰")
        print("=" * 60)
        
        # === æµ‹è¯•å‡åŽ‹ç¼© ===
        print("\nã€å‡åŽ‹ç¼©ã€‘ä¸è°ƒç”¨LLM")
        print("-" * 50)
        
        session1 = self.async_session_maker()
        storage1 = PostgreSQLStorage(session1)
        memory_fake = MidTermMemoryWithLLM(
            storage1, 
            max_turns=10,
            enable_real_compression=False
        )
        
        try:
            user_id = "fake_user"
            session_id = "fake_session"
            
            print(f"  é˜¶æ®µ1ï¼šæ·»åŠ 70æ¡æ¶ˆæ¯ï¼ˆè§¦å‘ç¬¬1æ¬¡åŽ‹ç¼©ï¼‰")
            
            for i in range(70):
                role = "user" if i % 2 == 0 else "assistant"
                await memory_fake.add_message(user_id, session_id, role, f"æ¶ˆæ¯{i}")
            
            conv = await storage1.get_or_create_conversation(user_id, session_id)
            db_count = len(await storage1.query_messages(conv.id))
            summaries = await storage1.get_summaries(conv.id)
            
            print(f"    âœ“ PostgreSQL: {db_count}æ¡")
            print(f"    âœ“ æ‘˜è¦æ•°é‡: {len(summaries)}ä¸ª")
            
            # é˜¶æ®µ2ï¼šæ·»åŠ 48æ¡åˆ°98æ¡
            print(f"\n  é˜¶æ®µ2ï¼šæ·»åŠ 48æ¡åˆ°98æ¡")
            for i in range(48):
                role = "user" if i % 2 == 0 else "assistant"
                await memory_fake.add_message(user_id, session_id, role, f"è¿½åŠ {i}")
            
            db_count = len(await storage1.query_messages(conv.id))
            print(f"    âœ“ PostgreSQL: {db_count}æ¡")
            
            # é˜¶æ®µ3ï¼šæµ‹é‡ç¬¬99-100æ¡ï¼ˆè§¦å‘ç¬¬2æ¬¡åŽ‹ç¼©ï¼‰
            print(f"\n  é˜¶æ®µ3ï¼šæµ‹é‡ç¬¬99-100æ¡ï¼ˆè§¦å‘ç¬¬2æ¬¡åŽ‹ç¼©ï¼‰")
            start = time.time()
            await memory_fake.add_message(user_id, session_id, "user", "ç¬¬99æ¡")
            await memory_fake.add_message(user_id, session_id, "assistant", "ç¬¬100æ¡")
            fake_time = time.time() - start
            
            print(f"    âœ“ å‡åŽ‹ç¼©å»¶è¿Ÿ: {fake_time*1000:.2f} ms")
            
            self.results['fake_compression'] = {
                'latency': fake_time * 1000
            }
        
        finally:
            await session1.close()
        
        # === æµ‹è¯•çœŸå®žLLMåŽ‹ç¼© ===
        print("\nã€çœŸå®žLLMåŽ‹ç¼©ã€‘è°ƒç”¨DeepSeek API")
        print("-" * 50)
        
        api_key = os.getenv("DEEPSEEK_API_KEY")
        if not api_key:
            print("  âŒ æœªè®¾ç½®DEEPSEEK_API_KEYï¼Œè·³è¿‡çœŸå®žåŽ‹ç¼©æµ‹è¯•")
            self.results['real_compression'] = {
                'latency': 0,
                'skipped': True
            }
            return
        
        print(f"  âœ“ API Keyå·²è®¾ç½®: {api_key[:10]}...")
        
        session2 = self.async_session_maker()
        storage2 = PostgreSQLStorage(session2)
        memory_real = MidTermMemoryWithLLM(
            storage2,
            max_turns=10,
            enable_real_compression=True
        )
        
        try:
            user_id = "real_user"
            session_id = "real_session"
            
            print(f"  é˜¶æ®µ1ï¼šæ·»åŠ 70æ¡æ¶ˆæ¯ï¼ˆè§¦å‘ç¬¬1æ¬¡åŽ‹ç¼©ï¼‰")
            
            for i in range(70):
                role = "user" if i % 2 == 0 else "assistant"
                content = f"æˆ‘æ˜¯Tomï¼Œæˆ‘ä»Šå¹´28å²ï¼Œåœ¨ä¸Šæµ·å·¥ä½œã€‚è¿™æ˜¯ç¬¬{i}æ¡æ¶ˆæ¯ã€‚"
                await memory_real.add_message(user_id, session_id, role, content)
            
            conv = await storage2.get_or_create_conversation(user_id, session_id)
            db_count = len(await storage2.query_messages(conv.id))
            summaries = await storage2.get_summaries(conv.id)
            profiles = await storage2.get_profile(conv.id)
            
            print(f"    âœ“ PostgreSQL: {db_count}æ¡")
            print(f"    âœ“ æ‘˜è¦æ•°é‡: {len(summaries)}ä¸ª")
            if summaries:
                print(f"    âœ“ æ‘˜è¦å†…å®¹: {summaries[0].summary_text[:60]}...")
            if profiles:
                print(f"    âœ“ ç”¨æˆ·ç”»åƒ: {profiles}")
            
            # é˜¶æ®µ2ï¼šæ·»åŠ 48æ¡åˆ°98æ¡
            print(f"\n  é˜¶æ®µ2ï¼šæ·»åŠ 48æ¡åˆ°98æ¡")
            for i in range(48):
                role = "user" if i % 2 == 0 else "assistant"
                await memory_real.add_message(user_id, session_id, role, f"è¿½åŠ {i}")
            
            db_count = len(await storage2.query_messages(conv.id))
            print(f"    âœ“ PostgreSQL: {db_count}æ¡")
            
            # é˜¶æ®µ3ï¼šæµ‹é‡ç¬¬99-100æ¡ï¼ˆè§¦å‘ç¬¬2æ¬¡LLMåŽ‹ç¼©ï¼‰
            print(f"\n  é˜¶æ®µ3ï¼šæµ‹é‡ç¬¬99-100æ¡ï¼ˆè§¦å‘ç¬¬2æ¬¡LLMåŽ‹ç¼©ï¼‰")
            print(f"    â±ï¸  é¢„è®¡è€—æ—¶: 5-6ç§’...")
            
            start = time.time()
            await memory_real.add_message(user_id, session_id, "user", "æˆ‘å–œæ¬¢ç¼–ç¨‹å’ŒAI")
            await memory_real.add_message(user_id, session_id, "assistant", "å¾ˆé«˜å…´çŸ¥é“ä½ çš„å…´è¶£")
            real_time = time.time() - start
            
            print(f"    âœ“ çœŸå®žLLMåŽ‹ç¼©å»¶è¿Ÿ: {real_time*1000:.2f} ms ({real_time:.2f}ç§’)")
            
            self.results['real_compression'] = {
                'latency': real_time * 1000,
                'skipped': False
            }
        
        finally:
            await session2.close()
    
    async def test_compression_batch(self, count: int = 3):
        """
        æµ‹è¯•2ï¼šæ‰¹é‡åŽ‹ç¼©æµ‹è¯•ï¼ˆå®Œæ•´ä¿®å¤ç‰ˆï¼‰
        
        æ¯ä¸ªbatchç‹¬ç«‹æµ‹è¯•ï¼Œç¡®ä¿è§¦å‘LLMåŽ‹ç¼©
        """
        print(f"\nã€æµ‹è¯•2ã€‘æ‰¹é‡åŽ‹ç¼©æµ‹è¯•ï¼ˆ{count}æ¬¡ï¼Œç‹¬ç«‹å®žä¾‹ï¼‰")
        print("=" * 60)
        
        api_key = os.getenv("DEEPSEEK_API_KEY")
        if not api_key:
            print("  âŒ æœªè®¾ç½®DEEPSEEK_API_KEYï¼Œè·³è¿‡")
            return
        
        compression_times = []
        
        for batch in range(count):
            print(f"\nç¬¬{batch+1}æ¬¡æµ‹è¯•...")
            
            # åˆ›å»ºç‹¬ç«‹çš„sessionå’Œmemory
            session = self.async_session_maker()
            storage = PostgreSQLStorage(session)
            memory = MidTermMemoryWithLLM(
                storage,
                max_turns=10,
                enable_real_compression=True
            )
            
            try:
                user_id = f"batch_user_{batch}"
                session_id = f"batch_session_{batch}"
                
                # é˜¶æ®µ1ï¼šæ·»åŠ 70æ¡ï¼ˆè§¦å‘ç¬¬1æ¬¡åŽ‹ç¼©ï¼‰
                print(f"  é˜¶æ®µ1ï¼šæ·»åŠ 70æ¡...")
                for i in range(70):
                    role = "user" if i % 2 == 0 else "assistant"
                    await memory.add_message(user_id, session_id, role, f"æ¶ˆæ¯{i}")
                
                conv = await storage.get_or_create_conversation(user_id, session_id)
                summaries = await storage.get_summaries(conv.id)
                print(f"    âœ“ æ‘˜è¦æ•°é‡: {len(summaries)}ä¸ª")
                
                if not summaries:
                    print(f"  âš ï¸  ç¬¬1æ¬¡åŽ‹ç¼©æœªè§¦å‘ï¼ˆè·³è¿‡ï¼‰")
                    continue
                
                # é˜¶æ®µ2ï¼šæ·»åŠ 28æ¡åˆ°78æ¡
                print(f"  é˜¶æ®µ2ï¼šæ·»åŠ 28æ¡åˆ°78æ¡...")
                for i in range(48):
                    role = "user" if i % 2 == 0 else "assistant"
                    await memory.add_message(user_id, session_id, role, f"è¿½åŠ {i}")
                
                db_count = len(await storage.query_messages(conv.id))
                print(f"    âœ“ PostgreSQL: {db_count}æ¡")
                
                # é˜¶æ®µ3ï¼šæµ‹é‡ç¬¬79-80æ¡ï¼ˆè§¦å‘ç¬¬2æ¬¡LLMåŽ‹ç¼©ï¼‰
                print(f"  é˜¶æ®µ3ï¼šæµ‹é‡ç¬¬79-80æ¡ï¼ˆè§¦å‘LLMåŽ‹ç¼©ï¼‰...")
                start = time.time()
                await memory.add_message(user_id, session_id, "user", "ç¬¬79æ¡")
                await memory.add_message(user_id, session_id, "assistant", "ç¬¬80æ¡")
                elapsed = time.time() - start
                
                compression_times.append(elapsed)
                print(f"    âœ“ å»¶è¿Ÿ: {elapsed*1000:.2f} ms ({elapsed:.2f}ç§’)")
            
            finally:
                await session.close()
        
        if compression_times:
            avg_time = sum(compression_times) / len(compression_times)
            max_time = max(compression_times)
            min_time = min(compression_times)
            
            print(f"\næ‰¹é‡æµ‹è¯•ç»“æžœï¼ˆ{len(compression_times)}æ¬¡æœ‰æ•ˆï¼‰:")
            print(f"  å¹³å‡å»¶è¿Ÿ: {avg_time*1000:.2f} ms ({avg_time:.2f}ç§’)")
            print(f"  æœ€å¤§å»¶è¿Ÿ: {max_time*1000:.2f} ms ({max_time:.2f}ç§’)")
            print(f"  æœ€å°å»¶è¿Ÿ: {min_time*1000:.2f} ms ({min_time:.2f}ç§’)")
            
            self.results['batch_compression'] = {
                'avg_latency': avg_time * 1000,
                'max_latency': max_time * 1000,
                'min_latency': min_time * 1000,
                'valid_count': len(compression_times)
            }
        else:
            print("\n  âŒ æ²¡æœ‰æœ‰æ•ˆçš„åŽ‹ç¼©æµ‹è¯•")
    
    def print_summary(self):
        """æ‰“å°æ€§èƒ½æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("LLMæ€§èƒ½æµ‹è¯•æ‘˜è¦")
        print("=" * 60)
        
        if 'fake_compression' not in self.results or 'real_compression' not in self.results:
            print("\næµ‹è¯•æœªå®Œæˆ")
            return
        
        print("\nã€å¯¹æ¯”ç»“æžœã€‘")
        fake = self.results['fake_compression']
        real = self.results['real_compression']
        
        print(f"  å‡åŽ‹ç¼©å»¶è¿Ÿ:      {fake['latency']:8.2f} ms")
        
        if not real.get('skipped'):
            print(f"  çœŸå®žLLMåŽ‹ç¼©å»¶è¿Ÿ: {real['latency']:8.2f} ms ({real['latency']/1000:.2f}ç§’)")
            
            if fake['latency'] > 0:
                ratio = real['latency'] / fake['latency']
                print(f"  å·®è·:            {real['latency'] - fake['latency']:8.2f} ms ({ratio:.0f}x)")
            
            if 'batch_compression' in self.results:
                batch = self.results['batch_compression']
                print(f"\nã€æ‰¹é‡æµ‹è¯•ã€‘ï¼ˆ{batch['valid_count']}æ¬¡æœ‰æ•ˆï¼‰")
                print(f"  å¹³å‡å»¶è¿Ÿ: {batch['avg_latency']:.2f} ms ({batch['avg_latency']/1000:.2f}ç§’)")
                print(f"  æœ€å¤§å»¶è¿Ÿ: {batch['max_latency']:.2f} ms ({batch['max_latency']/1000:.2f}ç§’)")
                print(f"  æœ€å°å»¶è¿Ÿ: {batch['min_latency']:.2f} ms ({batch['min_latency']/1000:.2f}ç§’)")
            
            print("\nã€å½±å“åˆ†æžã€‘")
            avg_latency = real['latency']
            if 'batch_compression' in self.results:
                avg_latency = self.results['batch_compression']['avg_latency']
            
            if avg_latency > 2000:
                print(f"  âŒ åŽ‹ç¼©å»¶è¿Ÿ >{avg_latency/1000:.1f}ç§’ï¼Œä¸¥é‡å½±å“ç”¨æˆ·ä½“éªŒ")
                print(f"  ðŸ’¡ å»ºè®®ï¼šå¿…é¡»ä½¿ç”¨å¼‚æ­¥åŽ‹ç¼©ï¼")
            elif avg_latency > 1000:
                print(f"  âš ï¸  åŽ‹ç¼©å»¶è¿Ÿ >{avg_latency/1000:.1f}ç§’ï¼Œå½±å“ç”¨æˆ·ä½“éªŒ")
                print(f"  ðŸ’¡ å»ºè®®ï¼šå¼ºçƒˆå»ºè®®ä½¿ç”¨å¼‚æ­¥åŽ‹ç¼©")
            elif avg_latency > 500:
                print(f"  âš ï¸  åŽ‹ç¼©å»¶è¿Ÿ >{avg_latency:.0f}msï¼Œæœ‰æ„ŸçŸ¥å»¶è¿Ÿ")
                print(f"  ðŸ’¡ å»ºè®®ï¼šè€ƒè™‘ä½¿ç”¨å¼‚æ­¥åŽ‹ç¼©")
            else:
                print(f"  âœ… åŽ‹ç¼©å»¶è¿Ÿ <500msï¼Œå¯æŽ¥å—")
        else:
            print("  âš ï¸  çœŸå®žLLMæµ‹è¯•å·²è·³è¿‡")
        
        print("\n" + "=" * 60)


async def main():
    """è¿è¡ŒLLMæ€§èƒ½æµ‹è¯•"""
    print("=" * 60)
    print("LLMåŽ‹ç¼©æ€§èƒ½æµ‹è¯•ï¼ˆå®Œæ•´ä¿®å¤ç‰ˆï¼‰")
    print("=" * 60)
    print(f"æ•°æ®åº“: {DB_URL}")
    
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("\nâš ï¸  è­¦å‘Šï¼šæœªè®¾ç½®DEEPSEEK_API_KEY")
        print("çœŸå®žLLMæµ‹è¯•å°†è¢«è·³è¿‡")
        print("\nè®¾ç½®æ–¹æ³•:")
        print("  1. åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶")
        print("  2. æ·»åŠ ï¼šDEEPSEEK_API_KEY=your-key")
        print()
    else:
        print(f"âœ“ DeepSeek API Keyå·²è®¾ç½®: {api_key[:10]}...")
    
    await ensure_database()
    
    test = LLMPerformanceTest()
    
    try:
        print("\nåˆå§‹åŒ–æµ‹è¯•çŽ¯å¢ƒ...")
        await test.setup()
        
        # è¿è¡Œæµ‹è¯•
        await test.test_fake_vs_real_compression()
        
        if api_key:
            await test.test_compression_batch(count=3)
        
        # æ‰“å°æ‘˜è¦
        test.print_summary()
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        await test.teardown()
        print("\næµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())