"""
çœŸå®Agentåœºæ™¯æ€§èƒ½æµ‹è¯• - æ”¹è¿›ç‰ˆ

åœºæ™¯ç‰¹ç‚¹ï¼š
1. å¤§è§„æ¨¡å†å²æ•°æ®ï¼šæ¯ç”¨æˆ·500æ¡å†å²æ¶ˆæ¯
2. é«˜é¢‘è¯»å–ï¼š80%è¯» + 20%å†™ï¼ˆæ¨¡æ‹ŸAgentå·¥ä½œæµï¼‰
3. å¤§æ‰¹é‡è¯»å–ï¼šæ¯æ¬¡è¯»50æ¡æ¶ˆæ¯ï¼ˆæ¨¡æ‹Ÿä¸Šä¸‹æ–‡çª—å£ï¼‰
4. å¹¶å‘å‹åŠ›ï¼š20ä¸ªç”¨æˆ·åŒæ—¶å¯¹è¯
"""
import asyncio
import time
import random
import statistics
import sys
from pathlib import Path
from typing import List, Dict
from dataclasses import dataclass

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.memory.mid_term_async import MidTermMemoryAsync
from src.memory.mid_term_with_redis import MidTermMemoryWithRedis
from src.memory.postgres_storage import PostgreSQLStorage
from src.memory.redis_storage import RedisStorage
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker


# ==================== æµ‹è¯•é…ç½® ====================

NUM_USERS = 20              # å¹¶å‘ç”¨æˆ·æ•°
HISTORY_MESSAGES = 500      # æ¯ç”¨æˆ·å†å²æ¶ˆæ¯æ•°
TEST_ROUNDS = 50            # æµ‹è¯•è½®æ•°
READ_RATIO = 0.8            # 80%æ“ä½œæ˜¯è¯»å–
CONTEXT_SIZE = 50           # æ¯æ¬¡è¯»å–50æ¡æ¶ˆæ¯ï¼ˆæ¨¡æ‹Ÿä¸Šä¸‹æ–‡çª—å£ï¼‰


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    latencies: List[float]
    read_latencies: List[float]
    write_latencies: List[float]
    total_time: float
    cache_hit_rate: float = 0.0
    
    @property
    def p50(self) -> float:
        return statistics.median(self.latencies) if self.latencies else 0
    
    @property
    def p95(self) -> float:
        if not self.latencies:
            return 0
        sorted_latencies = sorted(self.latencies)
        idx = int(len(sorted_latencies) * 0.95)
        return sorted_latencies[idx]
    
    @property
    def p99(self) -> float:
        if not self.latencies:
            return 0
        sorted_latencies = sorted(self.latencies)
        idx = int(len(sorted_latencies) * 0.99)
        return sorted_latencies[idx]
    
    @property
    def avg(self) -> float:
        return sum(self.latencies) / len(self.latencies) if self.latencies else 0
    
    @property
    def throughput(self) -> float:
        return len(self.latencies) / self.total_time if self.total_time > 0 else 0


async def prepare_history(
    session_maker,
    user_id: str,
    num_messages: int,
    use_redis: bool,
    redis_storage=None
) -> None:
    """å‡†å¤‡å†å²æ¶ˆæ¯ï¼ˆæ¨¡æ‹Ÿé•¿å¯¹è¯å†å²ï¼‰"""
    session = session_maker()
    pg_storage = PostgreSQLStorage(session)
    
    if use_redis:
        memory = MidTermMemoryWithRedis(
            pg_storage=pg_storage,
            redis_storage=redis_storage,
            max_turns=5,
            cache_ttl=300
        )
    else:
        memory = MidTermMemoryAsync(
            storage=pg_storage,
            max_turns=5,
            session_maker=session_maker
        )
    
    session_id = f"session_{user_id}"
    
    try:
        # æ‰¹é‡æ·»åŠ å†å²æ¶ˆæ¯
        for i in range(num_messages):
            await memory.add_message(
                user_id, session_id,
                "user" if i % 2 == 0 else "assistant",
                f"å†å²æ¶ˆæ¯ {i+1}",
                tokens=50
            )
        
    finally:
        await session.close()


async def simulate_agent_conversation(
    session_maker,
    user_id: str,
    num_rounds: int,
    read_ratio: float,
    context_size: int,
    use_redis: bool,
    redis_storage=None
) -> Dict[str, List[float]]:
    """
    æ¨¡æ‹ŸAgentå¯¹è¯å·¥ä½œæµ
    
    çœŸå®Agentæµç¨‹ï¼š
    1. è¯»å–å†å²ä¸Šä¸‹æ–‡ï¼ˆ50æ¡æ¶ˆæ¯ï¼‰
    2. æ„é€ prompt + è°ƒç”¨LLM
    3. å†™å…¥æ–°æ¶ˆæ¯
    
    æµ‹è¯•ä¸­ï¼š80%è¯» + 20%å†™
    """
    session = session_maker()
    pg_storage = PostgreSQLStorage(session)
    
    if use_redis:
        memory = MidTermMemoryWithRedis(
            pg_storage=pg_storage,
            redis_storage=redis_storage,
            max_turns=5,
            cache_ttl=300
        )
    else:
        memory = MidTermMemoryAsync(
            storage=pg_storage,
            max_turns=5,
            session_maker=session_maker
        )
    
    session_id = f"session_{user_id}"
    write_latencies = []
    read_latencies = []
    
    try:
        for round_num in range(num_rounds):
            operation = "read" if random.random() < read_ratio else "write"
            
            if operation == "read":
                # è¯»æ“ä½œï¼šè¯»å–å¤§é‡å†å²ä¸Šä¸‹æ–‡ï¼ˆæ¨¡æ‹Ÿç»™LLMçš„ä¸Šä¸‹æ–‡ï¼‰
                start = time.time()
                
                if use_redis:
                    await memory.query_messages(user_id, session_id, limit=context_size)
                else:
                    conv = await pg_storage.get_or_create_conversation(user_id, session_id)
                    await pg_storage.query_messages(conv.id, limit=context_size)
                
                elapsed = (time.time() - start) * 1000
                read_latencies.append(elapsed)
            
            else:
                # å†™æ“ä½œï¼šæ·»åŠ æ–°æ¶ˆæ¯
                start = time.time()
                
                await memory.add_message(
                    user_id, session_id,
                    "user" if round_num % 2 == 0 else "assistant",
                    f"æ–°æ¶ˆæ¯ round_{round_num}",
                    tokens=50
                )
                
                elapsed = (time.time() - start) * 1000
                write_latencies.append(elapsed)
        
        return {
            "write_latencies": write_latencies,
            "read_latencies": read_latencies,
            "cache_hit_rate": memory.get_cache_hit_rate() if use_redis else 0.0
        }
    
    finally:
        await session.close()


async def test_without_redis() -> PerformanceMetrics:
    """æµ‹è¯•ï¼šä¸å¸¦Redisç¼“å­˜"""
    print("\n" + "=" * 60)
    print("ã€æµ‹è¯•1ã€‘ä¸å¸¦Redisç¼“å­˜ï¼ˆçº¯PostgreSQLï¼‰")
    print("=" * 60)
    print(f"æ•°æ®è§„æ¨¡ï¼š{NUM_USERS}ä¸ªç”¨æˆ· Ã— {HISTORY_MESSAGES}æ¡å†å² = {NUM_USERS * HISTORY_MESSAGES:,}æ¡æ¶ˆæ¯")
    print(f"æµ‹è¯•è´Ÿè½½ï¼š{NUM_USERS}ä¸ªç”¨æˆ·å¹¶å‘ Ã— {TEST_ROUNDS}è½®å¯¹è¯")
    print(f"è¯»å†™æ¯”ä¾‹ï¼š{int(READ_RATIO*100)}%è¯» + {int((1-READ_RATIO)*100)}%å†™")
    print(f"è¯»å–è§„æ¨¡ï¼šæ¯æ¬¡è¯»å–{CONTEXT_SIZE}æ¡æ¶ˆæ¯ï¼ˆæ¨¡æ‹Ÿä¸Šä¸‹æ–‡çª—å£ï¼‰")
    
    # åˆ›å»ºæ•°æ®åº“è¿æ¥
    engine = create_async_engine(
        "postgresql+asyncpg://FiaShi@localhost/memory_chatbot_test",
        echo=False,
        pool_size=30,
        max_overflow=20
    )
    
    async_session_maker = sessionmaker(
        engine, class_=AsyncSession, expire_on_commit=False
    )
    
    try:
        # é˜¶æ®µ1ï¼šå‡†å¤‡å†å²æ•°æ®
        print(f"\né˜¶æ®µ1ï¼šå‡†å¤‡å†å²æ•°æ®...")
        prep_start = time.time()
        
        prep_tasks = []
        for user_idx in range(NUM_USERS):
            user_id = f"user_no_redis_{user_idx}"
            task = asyncio.create_task(
                prepare_history(
                    async_session_maker, user_id,
                    HISTORY_MESSAGES, use_redis=False
                )
            )
            prep_tasks.append(task)
        
        await asyncio.gather(*prep_tasks)
        prep_time = time.time() - prep_start
        print(f"âœ… å†å²æ•°æ®å‡†å¤‡å®Œæˆï¼è€—æ—¶: {prep_time:.2f}ç§’")
        
        # é˜¶æ®µ2ï¼šæµ‹è¯•è¯»å†™æ€§èƒ½
        print(f"\né˜¶æ®µ2ï¼šå¼€å§‹æ€§èƒ½æµ‹è¯•...")
        test_start = time.time()
        
        test_tasks = []
        for user_idx in range(NUM_USERS):
            user_id = f"user_no_redis_{user_idx}"
            task = asyncio.create_task(
                simulate_agent_conversation(
                    async_session_maker, user_id,
                    TEST_ROUNDS, READ_RATIO, CONTEXT_SIZE, use_redis=False
                )
            )
            test_tasks.append(task)
        
        results = await asyncio.gather(*test_tasks)
        test_time = time.time() - test_start
        
        # æ±‡æ€»ç»“æœ
        all_write_latencies = []
        all_read_latencies = []
        
        for result in results:
            all_write_latencies.extend(result["write_latencies"])
            all_read_latencies.extend(result["read_latencies"])
        
        all_latencies = all_write_latencies + all_read_latencies
        
        metrics = PerformanceMetrics(
            latencies=all_latencies,
            read_latencies=all_read_latencies,
            write_latencies=all_write_latencies,
            total_time=test_time,
            cache_hit_rate=0.0
        )
        
        print(f"âœ… æµ‹è¯•å®Œæˆï¼æ€»è€—æ—¶: {test_time:.2f}ç§’")
        return metrics
        
    finally:
        await engine.dispose()


async def test_with_redis() -> PerformanceMetrics:
    """æµ‹è¯•ï¼šå¸¦Redisç¼“å­˜"""
    print("\n" + "=" * 60)
    print("ã€æµ‹è¯•2ã€‘å¸¦Redisç¼“å­˜")
    print("=" * 60)
    print(f"æ•°æ®è§„æ¨¡ï¼š{NUM_USERS}ä¸ªç”¨æˆ· Ã— {HISTORY_MESSAGES}æ¡å†å² = {NUM_USERS * HISTORY_MESSAGES:,}æ¡æ¶ˆæ¯")
    print(f"æµ‹è¯•è´Ÿè½½ï¼š{NUM_USERS}ä¸ªç”¨æˆ·å¹¶å‘ Ã— {TEST_ROUNDS}è½®å¯¹è¯")
    print(f"è¯»å†™æ¯”ä¾‹ï¼š{int(READ_RATIO*100)}%è¯» + {int((1-READ_RATIO)*100)}%å†™")
    print(f"è¯»å–è§„æ¨¡ï¼šæ¯æ¬¡è¯»å–{CONTEXT_SIZE}æ¡æ¶ˆæ¯ï¼ˆæ¨¡æ‹Ÿä¸Šä¸‹æ–‡çª—å£ï¼‰")
    
    # åˆ›å»ºæ•°æ®åº“è¿æ¥
    engine = create_async_engine(
        "postgresql+asyncpg://FiaShi@localhost/memory_chatbot_test",
        echo=False,
        pool_size=30,
        max_overflow=20
    )
    
    async_session_maker = sessionmaker(
        engine, class_=AsyncSession, expire_on_commit=False
    )
    
    # åˆ›å»ºRedisè¿æ¥
    redis_storage = RedisStorage()
    await redis_storage.connect()
    
    try:
        # é˜¶æ®µ1ï¼šå‡†å¤‡å†å²æ•°æ®
        print(f"\né˜¶æ®µ1ï¼šå‡†å¤‡å†å²æ•°æ®...")
        prep_start = time.time()
        
        prep_tasks = []
        for user_idx in range(NUM_USERS):
            user_id = f"user_with_redis_{user_idx}"
            task = asyncio.create_task(
                prepare_history(
                    async_session_maker, user_id,
                    HISTORY_MESSAGES, use_redis=True,
                    redis_storage=redis_storage
                )
            )
            prep_tasks.append(task)
        
        await asyncio.gather(*prep_tasks)
        prep_time = time.time() - prep_start
        print(f"âœ… å†å²æ•°æ®å‡†å¤‡å®Œæˆï¼è€—æ—¶: {prep_time:.2f}ç§’")
        
        # é˜¶æ®µ2ï¼šæµ‹è¯•è¯»å†™æ€§èƒ½
        print(f"\né˜¶æ®µ2ï¼šå¼€å§‹æ€§èƒ½æµ‹è¯•...")
        test_start = time.time()
        
        test_tasks = []
        for user_idx in range(NUM_USERS):
            user_id = f"user_with_redis_{user_idx}"
            task = asyncio.create_task(
                simulate_agent_conversation(
                    async_session_maker, user_id,
                    TEST_ROUNDS, READ_RATIO, CONTEXT_SIZE, use_redis=True,
                    redis_storage=redis_storage
                )
            )
            test_tasks.append(task)
        
        results = await asyncio.gather(*test_tasks)
        test_time = time.time() - test_start
        
        # æ±‡æ€»ç»“æœ
        all_write_latencies = []
        all_read_latencies = []
        cache_hit_rates = []
        
        for result in results:
            all_write_latencies.extend(result["write_latencies"])
            all_read_latencies.extend(result["read_latencies"])
            cache_hit_rates.append(result["cache_hit_rate"])
        
        all_latencies = all_write_latencies + all_read_latencies
        avg_cache_hit_rate = sum(cache_hit_rates) / len(cache_hit_rates) if cache_hit_rates else 0
        
        metrics = PerformanceMetrics(
            latencies=all_latencies,
            read_latencies=all_read_latencies,
            write_latencies=all_write_latencies,
            total_time=test_time,
            cache_hit_rate=avg_cache_hit_rate
        )
        
        print(f"âœ… æµ‹è¯•å®Œæˆï¼æ€»è€—æ—¶: {test_time:.2f}ç§’")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        for user_idx in range(NUM_USERS):
            user_id = f"user_with_redis_{user_idx}"
            session_id = f"session_{user_id}"
            await redis_storage.redis.delete(
                redis_storage._message_list_key(user_id, session_id)
            )
        
        return metrics
        
    finally:
        await redis_storage.close()
        await engine.dispose()


def print_metrics(name: str, metrics: PerformanceMetrics):
    """æ‰“å°æ€§èƒ½æŒ‡æ ‡"""
    print(f"\nğŸ“Š {name} æ€§èƒ½æŠ¥å‘Š")
    print("=" * 60)
    
    print(f"\nã€å»¶è¿Ÿåˆ†å¸ƒã€‘")
    print(f"  P50 (ä¸­ä½æ•°): {metrics.p50:.2f}ms")
    print(f"  P95 (95åˆ†ä½): {metrics.p95:.2f}ms")
    print(f"  P99 (99åˆ†ä½): {metrics.p99:.2f}ms")
    print(f"  å¹³å‡å»¶è¿Ÿ: {metrics.avg:.2f}ms")
    
    print(f"\nã€è¯»å†™æ€§èƒ½ã€‘")
    if metrics.read_latencies:
        read_avg = sum(metrics.read_latencies) / len(metrics.read_latencies)
        read_p95 = sorted(metrics.read_latencies)[int(len(metrics.read_latencies) * 0.95)]
        print(f"  è¯»æ“ä½œå¹³å‡: {read_avg:.2f}ms")
        print(f"  è¯»æ“ä½œP95: {read_p95:.2f}ms")
        print(f"  è¯»æ“ä½œæ¬¡æ•°: {len(metrics.read_latencies)}æ¬¡")
    if metrics.write_latencies:
        write_avg = sum(metrics.write_latencies) / len(metrics.write_latencies)
        print(f"  å†™æ“ä½œå¹³å‡: {write_avg:.2f}ms")
        print(f"  å†™æ“ä½œæ¬¡æ•°: {len(metrics.write_latencies)}æ¬¡")
    
    print(f"\nã€æ•´ä½“æ€§èƒ½ã€‘")
    print(f"  æ€»è¯·æ±‚æ•°: {len(metrics.latencies)}ä¸ª")
    print(f"  æ€»è€—æ—¶: {metrics.total_time:.2f}ç§’")
    print(f"  ååé‡: {metrics.throughput:.2f}è¯·æ±‚/ç§’")
    
    if metrics.cache_hit_rate > 0:
        print(f"\nã€ç¼“å­˜æ•ˆæœã€‘")
        print(f"  ç¼“å­˜å‘½ä¸­ç‡: {metrics.cache_hit_rate:.2%}")


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("=" * 60)
    print("ğŸš€ çœŸå®Agentåœºæ™¯æ€§èƒ½æµ‹è¯• - æ”¹è¿›ç‰ˆ")
    print("=" * 60)
    print(f"\næµ‹è¯•é…ç½®ï¼š")
    print(f"  å¹¶å‘ç”¨æˆ·: {NUM_USERS}ä¸ª")
    print(f"  å†å²æ¶ˆæ¯: æ¯ç”¨æˆ·{HISTORY_MESSAGES}æ¡")
    print(f"  æµ‹è¯•è½®æ•°: æ¯ç”¨æˆ·{TEST_ROUNDS}è½®")
    print(f"  æ€»äº¤äº’: {NUM_USERS * TEST_ROUNDS}æ¬¡")
    print(f"  è¯»å†™æ¯”ä¾‹: {int(READ_RATIO*100)}%è¯» / {int((1-READ_RATIO)*100)}%å†™")
    print(f"  ä¸Šä¸‹æ–‡çª—å£: {CONTEXT_SIZE}æ¡æ¶ˆæ¯")
    
    # æµ‹è¯•1ï¼šä¸å¸¦Redis
    metrics_no_redis = await test_without_redis()
    
    # ç­‰å¾…1ç§’
    await asyncio.sleep(1)
    
    # æµ‹è¯•2ï¼šå¸¦Redis
    metrics_with_redis = await test_with_redis()
    
    # æ‰“å°è¯¦ç»†æŠ¥å‘Š
    print_metrics("ä¸å¸¦Redis", metrics_no_redis)
    print_metrics("å¸¦Redis", metrics_with_redis)
    
    # å¯¹æ¯”åˆ†æ
    print("\n" + "=" * 60)
    print("ğŸ¯ æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("=" * 60)
    
    print(f"\nã€å…³é”®æŒ‡æ ‡å¯¹æ¯”ã€‘")
    
    # P50å¯¹æ¯”
    print(f"\nP50å»¶è¿Ÿï¼ˆä¸­ä½æ•°ï¼‰ï¼š")
    print(f"  ä¸å¸¦Redis: {metrics_no_redis.p50:.2f}ms")
    print(f"  å¸¦Redis:   {metrics_with_redis.p50:.2f}ms")
    p50_improvement = metrics_no_redis.p50 / metrics_with_redis.p50 if metrics_with_redis.p50 > 0 else 0
    if p50_improvement > 1:
        print(f"  âœ… æå‡: {p50_improvement:.2f}x")
    else:
        print(f"  âš ï¸ å˜åŒ–: {p50_improvement:.2f}x")
    
    # P95å¯¹æ¯”
    print(f"\nP95å»¶è¿Ÿï¼ˆ95åˆ†ä½ï¼‰ï¼š")
    print(f"  ä¸å¸¦Redis: {metrics_no_redis.p95:.2f}ms")
    print(f"  å¸¦Redis:   {metrics_with_redis.p95:.2f}ms")
    p95_improvement = metrics_no_redis.p95 / metrics_with_redis.p95 if metrics_with_redis.p95 > 0 else 0
    if p95_improvement > 1:
        print(f"  âœ… æå‡: {p95_improvement:.2f}x")
    else:
        print(f"  âš ï¸ å˜åŒ–: {p95_improvement:.2f}x")
    
    # è¯»æ“ä½œå¯¹æ¯”ï¼ˆæœ€å…³é”®ï¼‰
    if metrics_with_redis.read_latencies and metrics_no_redis.read_latencies:
        read_avg_no_redis = sum(metrics_no_redis.read_latencies) / len(metrics_no_redis.read_latencies)
        read_avg_with_redis = sum(metrics_with_redis.read_latencies) / len(metrics_with_redis.read_latencies)
        read_p95_no_redis = sorted(metrics_no_redis.read_latencies)[int(len(metrics_no_redis.read_latencies) * 0.95)]
        read_p95_with_redis = sorted(metrics_with_redis.read_latencies)[int(len(metrics_with_redis.read_latencies) * 0.95)]
        
        read_improvement = read_avg_no_redis / read_avg_with_redis if read_avg_with_redis > 0 else 0
        read_p95_improvement = read_p95_no_redis / read_p95_with_redis if read_p95_with_redis > 0 else 0
        
        print(f"\nğŸ“– è¯»æ“ä½œæ€§èƒ½ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰ï¼š")
        print(f"  å¹³å‡å»¶è¿Ÿï¼š")
        print(f"    ä¸å¸¦Redis: {read_avg_no_redis:.2f}ms")
        print(f"    å¸¦Redis:   {read_avg_with_redis:.2f}ms")
        if read_improvement > 1:
            print(f"    âœ… æå‡: {read_improvement:.2f}x")
        else:
            print(f"    âš ï¸ å˜åŒ–: {read_improvement:.2f}x")
        
        print(f"  P95å»¶è¿Ÿï¼š")
        print(f"    ä¸å¸¦Redis: {read_p95_no_redis:.2f}ms")
        print(f"    å¸¦Redis:   {read_p95_with_redis:.2f}ms")
        if read_p95_improvement > 1:
            print(f"    âœ… æå‡: {read_p95_improvement:.2f}x")
        else:
            print(f"    âš ï¸ å˜åŒ–: {read_p95_improvement:.2f}x")
    
    # ååé‡å¯¹æ¯”
    print(f"\nååé‡ï¼š")
    print(f"  ä¸å¸¦Redis: {metrics_no_redis.throughput:.2f}è¯·æ±‚/ç§’")
    print(f"  å¸¦Redis:   {metrics_with_redis.throughput:.2f}è¯·æ±‚/ç§’")
    throughput_improvement = metrics_with_redis.throughput / metrics_no_redis.throughput if metrics_no_redis.throughput > 0 else 0
    if throughput_improvement > 1:
        print(f"  âœ… æå‡: {throughput_improvement:.2f}x")
    else:
        print(f"  âš ï¸ å˜åŒ–: {throughput_improvement:.2f}x")
    
    # æ€»è€—æ—¶å¯¹æ¯”
    print(f"\næ€»è€—æ—¶ï¼š")
    print(f"  ä¸å¸¦Redis: {metrics_no_redis.total_time:.2f}ç§’")
    print(f"  å¸¦Redis:   {metrics_with_redis.total_time:.2f}ç§’")
    time_saved = metrics_no_redis.total_time - metrics_with_redis.total_time
    time_saved_pct = (time_saved / metrics_no_redis.total_time) * 100 if metrics_no_redis.total_time > 0 else 0
    if time_saved > 0:
        print(f"  âœ… èŠ‚çœ: {time_saved:.2f}ç§’ ({time_saved_pct:.1f}%)")
    else:
        print(f"  âš ï¸ å¢åŠ : {abs(time_saved):.2f}ç§’ ({abs(time_saved_pct):.1f}%)")
    
    # ç¼“å­˜æ•ˆæœ
    print(f"\nç¼“å­˜æ•ˆæœï¼š")
    print(f"  ç¼“å­˜å‘½ä¸­ç‡: {metrics_with_redis.cache_hit_rate:.2%}")
    
    print("\n" + "=" * 60)
    print("âœ… çœŸå®åœºæ™¯æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    
    # æ€»ç»“
    print(f"\nğŸ’¡ å…³é”®å‘ç°ï¼š")
    print(f"  1. æ•°æ®è§„æ¨¡: {NUM_USERS * HISTORY_MESSAGES:,}æ¡å†å²æ¶ˆæ¯")
    print(f"  2. è¯»æ“ä½œå æ¯”: {int(READ_RATIO*100)}% (æ¯æ¬¡è¯»å–{CONTEXT_SIZE}æ¡)")
    if read_improvement > 1:
        print(f"  3. è¯»æ“ä½œæ€§èƒ½æå‡: {read_improvement:.1f}å€")
    print(f"  4. ç¼“å­˜å‘½ä¸­ç‡: {metrics_with_redis.cache_hit_rate:.1%}")
    if p95_improvement > 1:
        print(f"  5. P95å»¶è¿Ÿé™ä½: {p95_improvement:.1f}å€")


if __name__ == "__main__":
    asyncio.run(main())